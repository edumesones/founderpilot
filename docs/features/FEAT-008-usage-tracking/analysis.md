# FEAT-008: Critical Analysis

> Generated by Think Critically protocol (Phase 2 of Feature Cycle)
> **Depth:** Full (11 steps)
> **Date:** 2026-02-03

---

## 1. Problem Clarification

### Problem Statement
Track and report usage of FounderPilot agents (InboxPilot, InvoicePilot, MeetingPilot) per tenant to enable plan limit enforcement, overage billing, and user visibility into consumption.

### Hard Constraints
- Must integrate with existing Stripe subscription system (FEAT-002)
- Must support Stripe metered billing API for overage reporting
- Must handle concurrent writes from multiple workers
- Must maintain audit trail of all usage events
- Performance: API response < 200ms for usage stats query
- Data accuracy: usage counts must match actual agent actions within 1% tolerance

### Soft Constraints
- Prefer PostgreSQL over separate time-series DB (simplicity)
- Prefer batch reporting to Stripe over real-time (cost + reliability)
- UI updates via polling acceptable (avoid WebSockets complexity)

### Success Criteria
- 100% of agent actions tracked with < 1s latency
- Usage API endpoint responds in < 200ms p95
- Overage billing reports to Stripe with 99.9% reliability
- Zero data loss of usage events
- Counter reconciliation job detects < 0.1% discrepancies

### Non-Goals
- Real-time WebSocket updates to UI
- Historical usage analytics dashboard
- Predictive usage forecasting
- Custom per-user alert thresholds

---

## 2. Implicit Assumptions ‚ö†Ô∏è

| # | Assumption | If Wrong, Impact | Confidence | Category |
|---|------------|------------------|------------|----------|
| 1 | Subscription always has current_period_start/end set | Counter creation fails, usage not tracked | **High** | Data Model |
| 2 | Stripe metered billing supports our volume (< 1000 reports/day) | Rate limits, failed reports | **Medium** | External API |
| 3 | Agent code will reliably call UsageTracker service | Undercounting, revenue loss | **Medium** | Integration |
| 4 | PostgreSQL write throughput sufficient for usage events (est. 100-500 events/min) | DB bottleneck, event loss | **High** | Performance |
| 5 | Subscription period aligns with Stripe billing period | Overage calculated for wrong timeframe | **High** | Business Logic |
| 6 | Plan limits stored in plans.limits JSONB match Stripe product config | Incorrect limit enforcement | **Medium** | Data Consistency |
| 7 | Tenant ID is always available in agent execution context | Can't attribute usage to tenant | **High** | Architecture |
| 8 | Overage pricing is static ($0.02/email, etc.) | Hardcoded values need code change | **Low** | Pricing Model |
| 9 | Trial users have plan=NULL or special trial plan | Edge case handling for trials | **Medium** | Business Logic |
| 10 | Background jobs run reliably on schedule | Overage not reported, stale data | **Medium** | Infrastructure |

### ‚ö†Ô∏è Assumptions Requiring Validation
- [ ] **#2 - Stripe metered billing volume limits**: Validate with Stripe docs/support (Medium confidence, High impact if wrong)
- [ ] **#3 - Agent integration reliability**: Code review of agent implementations to ensure UsageTracker is called (Medium confidence, Critical impact)
- [ ] **#8 - Overage pricing flexibility**: Confirm with product if pricing might change dynamically (Low confidence, Medium impact)
- [ ] **#9 - Trial user handling**: Verify trial flow doesn't break usage tracking (Medium confidence, Medium impact)

---

## 3. Design Space Exploration

### Approach A: Events-Only (No Cache)
**Core idea:** Store only `usage_events` table, aggregate on-the-fly for API queries

**Pros:**
- Simplest data model
- No sync issues
- Perfect audit trail

**Cons:**
- Slow API queries (aggregating 1000s of events per tenant)
- Index heavy for performance
- Doesn't scale past 10k events/period

**Best when:** Low volume (< 100 events/month per tenant)
**Effort:** Low

### Approach B: Counter-Only (No Events)
**Core idea:** Single `usage_counters` table, increment atomically

**Pros:**
- Fast reads (single row lookup)
- Minimal storage
- Simple logic

**Cons:**
- **No audit trail** - critical flaw for billing disputes
- Hard to debug undercounting
- Can't reconstruct history if corrupted

**Best when:** Audit trail not required (not our case)
**Effort:** Low

### Approach C: Hybrid (Events + Counter Cache) ‚úÖ
**Core idea:** Store every event in `usage_events` for audit, maintain aggregated `usage_counters` for fast queries

**Pros:**
- Fast API reads (counters)
- Complete audit trail (events)
- Can reconcile and fix counter drift
- Supports compliance requirements

**Cons:**
- More storage (events never deleted for 90 days)
- Sync complexity (counter must match events)
- Two write operations per usage event

**Best when:** Need both performance AND audit trail (our requirement)
**Effort:** Medium

### Preliminary Recommendation
**Approach C (Hybrid)** - The audit trail is non-negotiable for billing, and fast API reads are critical for UX. The sync complexity is manageable with a daily reconciliation job. This is industry standard for usage-based billing systems.

---

## 4. Trade-off Analysis

### Trade-off 1: Storage Cost vs Query Performance
**Position:** Favor **Query Performance** (counter cache) over storage savings
**Implications:**
- Accept 2x writes per usage event
- Accept storage cost of keeping events for 90 days
- Enables < 200ms API response time
- Justification: Storage is cheap, slow UI is expensive (user churn)

### Trade-off 2: Real-time Stripe Reporting vs Batch Reporting
**Position:** Favor **Batch Reporting** (daily + end-of-period)
**Implications:**
- Overage charges appear 1 day after incurred (acceptable delay)
- Reduced Stripe API calls (fewer rate limit issues)
- Easier to handle Stripe API failures (retry batch, not individual)
- Simpler implementation than event-driven reporting
- Justification: Near-real-time is sufficient for overage billing, not time-critical

### Trade-off 3: Blocking on Limit vs Allow Overage
**Position:** Favor **Allow Overage** (no blocking)
**Implications:**
- Better UX - user never blocked mid-task
- Revenue opportunity (overage fees)
- Requires clear communication of overage costs
- Needs in-app alerts before hitting limit
- Justification: Aligns with SaaS best practices (Stripe, Twilio model)

### Trade-off 4: WebSockets vs Polling for UI Updates
**Position:** Favor **Polling** (30s interval on dashboard page)
**Implications:**
- Simpler infrastructure (no WebSocket server)
- Slightly stale data (max 30s delay)
- Lower operational complexity
- Acceptable for non-critical usage stats display
- Justification: Usage stats aren't time-critical, defer WebSockets to v1.1

---

## 5. Failure-First Analysis

### Critical Failures (High Severity)

| Failure Mode | Probability | Severity | Detection | Mitigation |
|--------------|-------------|----------|-----------|------------|
| Usage events not recorded ‚Üí undercounting ‚Üí revenue loss | Medium | **Critical** | Reconciliation job flags discrepancy | Retry logic on event write, transaction guarantees, alerting |
| Counter drift from events ‚Üí incorrect billing | Low | **Critical** | Daily reconciliation job | Auto-correct counter from events sum, alert if delta > 5% |
| Stripe API down during overage report ‚Üí no charges | Low | **High** | Report failure logged + alerted | Retry with exponential backoff, queue failed reports for next batch |
| Background job fails silently ‚Üí overage never reported | Low | **Critical** | Job monitoring + heartbeat alerts | Dead-man switch alert if job not run in 25 hours, manual failover |

### Likely Failures (High Probability)

| Failure Mode | Probability | Severity | Detection | Mitigation |
|--------------|-------------|----------|-----------|------------|
| DB write contention under load | Medium | Low | Slow writes, timeout logs | Connection pooling, async writes, batching |
| API timeout on complex usage query | Low | Low | 500 errors, latency monitoring | Indexed queries, counter cache ensures fast reads |
| Stale counter displayed in UI | Medium | Low | User reports, reconciliation | Polling keeps data fresh enough, document 30s lag |

### Cascading Failures
- If **DB write fails** ‚Üí event not recorded ‚Üí counter not incremented ‚Üí undercounting ‚Üí user surprised by not hitting limit ‚Üí **potential revenue loss**
- If **Stripe webhook for period change delayed** ‚Üí counter not reset ‚Üí old period counter accumulates ‚Üí overage calculated incorrectly ‚Üí **incorrect billing**
- If **Reconciliation job fails AND counter drifts** ‚Üí incorrect usage displayed ‚Üí user makes decisions on bad data ‚Üí **trust erosion**

---

## 6. Boundaries & Invariants

### Invariants (Must ALWAYS be true)
1. **`sum(usage_events.quantity WHERE period) == usage_counter.count`** (within reconciliation tolerance)
2. **`usage_counter.period_start == subscription.current_period_start`** (counter aligned with billing period)
3. **`usage_events.tenant_id` always set** (no orphaned events)
4. **`usage_counter.count >= 0`** (never negative usage)

### Boundaries (Hard limits)

| Boundary | Limit | Enforcement |
|----------|-------|-------------|
| Max events per tenant per period | 100,000 | Soft limit - log warning if exceeded (likely bad actor) |
| Max API requests per tenant | 10 req/min | Rate limit middleware |
| Event retention | 90 days | Background cleanup job |
| Stripe report batch size | 1000 tenants/batch | Pagination in reporting job |

### What the System Will NEVER Do
- Block user when exceeding limit (business decision)
- Delete usage events before 90 days (compliance)
- Report usage to Stripe in real-time per event (performance)
- Expose usage data across tenants (security)

---

## 7. Observability & Control

### Key Metrics

| Metric | Purpose | Alert Threshold |
|--------|---------|-----------------|
| `usage_events_total` (Counter) | Track total events recorded | N/A (monotonic) |
| `usage_api_latency` (Histogram) | Monitor API performance | p95 > 300ms |
| `stripe_report_success_rate` (Gauge) | Overage reporting health | < 95% |
| `counter_drift_percentage` (Gauge) | Data accuracy | > 1% |
| `usage_events_write_errors` (Counter) | Data loss risk | > 10/hour |

### Essential Logs
- **Event creation:** `INFO: UsageEvent created: tenant={uuid}, agent={inbox}, action={email_processed}, quantity=1`
- **Counter increment:** `DEBUG: UsageCounter incremented: tenant={uuid}, agent={inbox}, new_count=425`
- **Overage detected:** `WARNING: Overage detected: tenant={uuid}, agent={invoice}, overage=5, cost_cents=50`
- **Stripe report:** `INFO: Stripe usage report success: tenant={uuid}, subscription_item={si_xxx}, quantity=5`
- **Reconciliation:** `WARNING: Counter drift detected: tenant={uuid}, agent={inbox}, counter=500, events_sum=497, diff=3`

### Debug Capabilities
- Query all events for specific tenant/period: `SELECT * FROM usage_events WHERE tenant_id=? AND created_at BETWEEN ? AND ?`
- Manually trigger reconciliation for tenant: `/admin/usage/reconcile/{tenant_id}`
- Force Stripe report for tenant: `/admin/usage/report/{tenant_id}`

### Manual Controls
- Admin can reset counter (with audit log)
- Admin can adjust usage (with reason field in event metadata)
- Admin can pause/resume background jobs

---

## 8. Reversibility & Entropy

### Decision Reversibility

| Decision | Reversibility | Cost to Reverse | Time to Reverse |
|----------|---------------|-----------------|-----------------|
| Hybrid events+counter model | **Hard** | High - requires data migration | 2-3 days |
| PostgreSQL storage | **Medium** | Medium - could add TimescaleDB | 1 week |
| Batch Stripe reporting | **Easy** | Low - just change job schedule | 1 day |
| Polling UI updates | **Easy** | Medium - add WebSocket server | 2-3 days |
| Overage pricing in code | **Medium** | Low - refactor to DB config | 1 day |

### Entropy Analysis
- **State accumulation:** Usage events grow linearly with tenant activity (~100-500 events/tenant/month). At 1000 tenants = 500k events/month. After 90 days = 1.5M events. Manageable with partitioning.
- **Complexity growth:** Each new agent type requires:
  - New enum value for `agent` field (simple)
  - New limits in plan config (simple)
  - New overage pricing (simple)
  - Integration point in agent code to call UsageTracker (one-time)
- **Migration path:** If we outgrow PostgreSQL, can migrate to TimescaleDB (PostgreSQL extension) or ClickHouse without major architectural changes. Events table is append-only, easy to export/import.

---

## 9. Adversarial Review üî¥

### Over-engineering Concerns
- **Concern:** Daily reconciliation job might be overkill
  - **Simpler alternative:** Weekly reconciliation
  - **Counter-argument:** Daily catches issues faster, prevents accumulating errors
- **Concern:** Storing every event for 90 days seems excessive
  - **Simpler alternative:** 30 days retention
  - **Counter-argument:** Billing disputes can arise 60+ days later, 90 days is safer

### Under-engineering Concerns
- **Concern:** No idempotency key on usage event writes
  - **Risk:** Duplicate events if retry on failure
  - **Mitigation:** Add `idempotency_key` field (e.g., `{tenant_id}-{agent}-{resource_id}-{timestamp}`)
- **Concern:** No circuit breaker for Stripe API calls
  - **Risk:** Repeated failures hammer Stripe API
  - **Mitigation:** Add circuit breaker pattern (after 5 failures, pause 15 min)

### The 2AM Incident
**Most likely production emergency:** Counter drift not detected for 2 weeks, accumulated 15% error for high-volume tenant, they're charged $500 overage but should be $425. Customer disputes charge.

**How it happens:**
1. Reconciliation job has bug, doesn't flag drift
2. High-volume tenant generates 5000 events/month
3. Counter increments fail silently for 5% of writes (DB contention)
4. Month ends, Stripe charged based on incorrect counter
5. Customer sees bill, compares to their records, disputes

**Prevention:**
- **Strong reconciliation:** Fail-loud if drift > 1%
- **Idempotency:** Ensure each event recorded exactly once
- **Transaction guarantees:** Event write + counter increment in same transaction
- **Customer-visible usage:** User can see usage in real-time, catches errors early

### Future Pain Points
- **Scaling to 10k+ tenants:** Current batch job might timeout, need sharding
- **Introducing new agent:** Need to update all limits, overage config, cumbersome
  - **Solution:** Move overage pricing to database config table (v1.1)
- **Historical analytics:** Current model only supports current period, adding historical requires aggregation tables
  - **Solution:** Acceptable limitation, defer to v1.1

### Security Concerns
- **Potential vulnerability:** API endpoint leaks usage data of other tenants if tenant_id validation bypassed
  - **Attack vector:** Manipulated JWT or SQL injection
  - **Mitigation:** Strict tenant_id validation at API layer, use ORM parameterized queries
- **Potential vulnerability:** Background job credentials compromised
  - **Attack vector:** Attacker could forge usage events or reset counters
  - **Mitigation:** Job runs with minimal DB permissions (write only to usage tables), audit all writes

### Scale Concerns
- **What breaks at scale:** At 10k tenants x 500 events/month = 5M events/month. PostgreSQL table grows to 50M rows in 10 months.
  - **How it breaks:** Queries slow, indexes bloated
  - **Solution:** Partition table by month (`usage_events_2024_01`, etc.), archive old partitions

### üö© Red Flags Found
- ‚ö†Ô∏è **Yellow Flag (Minor):** Overage pricing hardcoded in business logic instead of database config - limits flexibility
  - **Impact:** Low (pricing changes are infrequent)
  - **Fix:** Refactor to DB config in v1.1
- ‚ö†Ô∏è **Yellow Flag (Minor):** No idempotency on event writes - risk of duplicate charges under retry
  - **Impact:** Medium (rare, but customer-facing)
  - **Fix:** Add idempotency_key field NOW (low effort, high value)

**No critical red flags found** - approach is sound for MVP.

---

## 10. AI Delegation Matrix

### Safe for Full AI Automation (Ralph Loop)
- **Database models:** UsageEvent, UsageCounter SQLAlchemy models - straightforward CRUD
- **API endpoint:** GET /api/v1/usage - standard FastAPI endpoint with Pydantic schemas
- **Background jobs:** Reset, report, reconcile - well-defined logic, testable
- **Unit tests:** Coverage for overage calculation, counter logic, API responses

### AI with Human Review
- **Stripe integration:** Metered billing API calls - review error handling, retry logic
- **DB transaction logic:** Event + counter write atomicity - critical for correctness
- **Reconciliation algorithm:** Edge cases like period transitions - needs validation
- **Frontend UsageWidget:** UX decisions on colors, alerts, copy

### Human Only
- **Overage pricing decisions:** Business decision, not technical
- **Alert threshold tuning:** Requires product judgment (80% vs 90%)
- **Background job schedule:** Production timing considerations

---

## 11. Decision Summary

### Recommended Approach
**Hybrid events + counter cache model** with daily background jobs for reset, reporting, and reconciliation. PostgreSQL storage for simplicity, batch reporting to Stripe for reliability, polling-based UI for MVP. Allow overage (no blocking) with clear in-app alerts.

This approach balances:
- **Audit trail** (compliance, dispute resolution)
- **Performance** (fast API queries)
- **Reliability** (batch reporting, retry logic)
- **Simplicity** (leverage existing PostgreSQL, no new infra)

### Key Decisions Made

| Decision | Choice | Rationale |
|----------|--------|-----------|
| Storage model | Hybrid (events + counters) | Audit trail + performance |
| Database | PostgreSQL | Existing infra, sufficient for scale |
| Overage handling | Allow + charge | Better UX, revenue opportunity |
| Stripe reporting | Batch (daily + end-of-period) | Reliability, reduced API load |
| UI updates | Polling (30s) | Simplicity, defer WebSockets |
| Event idempotency | Add idempotency_key field | Prevent duplicate charges |
| Circuit breaker | Add for Stripe API | Protect against cascading failures |

### Short-term Goals (This Implementation)
1. Implement UsageEvent and UsageCounter models with idempotency
2. Build UsageTracker service with transaction guarantees
3. Create GET /api/v1/usage endpoint with < 200ms response
4. Build 3 background jobs (reset, report, reconcile)
5. Add Stripe metered billing integration with circuit breaker
6. Create frontend UsageWidget with progress bars + alerts
7. Write comprehensive tests for overage calculation

### Long-term Considerations
- **v1.1:** Move overage pricing to database config table
- **v1.1:** Add historical usage graphs (requires aggregation tables)
- **v1.1:** WebSocket real-time updates for power users
- **v2.0:** Partition usage_events table by month as data grows
- **v2.0:** Evaluate TimescaleDB for time-series optimizations

### Remaining Unknowns
- [ ] **Stripe metered billing limits:** Confirm max reports/day, rate limits
- [ ] **Trial user limits:** Confirm trial plan limits or no-limit policy
- [ ] **Background job infrastructure:** Confirm we have Celery/ARQ or equivalent

### Security Threat Model

| Threat | Likelihood | Impact | Mitigation |
|--------|------------|--------|------------|
| Tenant data leakage via API | Low | High | Strict tenant_id validation, auth middleware |
| SQL injection in usage query | Low | High | Use ORM with parameterized queries |
| Duplicate events via replay attack | Medium | Medium | Idempotency key, rate limiting |
| Compromised job credentials | Low | High | Minimal permissions, audit logs |

### Blast Radius Analysis
- If **UsageTracker service fails:** Events not recorded, undercounting, but agents continue functioning ‚Üí Isolated to billing accuracy
- If **Background jobs fail:** Overage not reported to Stripe, counters not reset ‚Üí Isolated to billing, no agent downtime
- If **Database fails:** All services impacted (not just usage tracking) ‚Üí System-wide failure
- **Maximum blast radius:** Billing accuracy + customer trust (if undercounting not caught). Does NOT impact agent functionality.

### Confidence Level
**High** ‚Äî This is a well-understood domain (usage metering) with established patterns. Key risks (counter drift, Stripe API reliability) have clear mitigations. Architecture is sound for MVP scale (< 1000 tenants). Only unknowns are external (Stripe limits), easily validated.

### Red Flags to Watch
- Counter drift > 1% in first week ‚Üí investigate DB transaction guarantees
- Stripe API failures > 5% ‚Üí add circuit breaker, evaluate batch size
- API latency > 200ms p95 ‚Üí optimize counter query indexing
- Reconciliation job detects systematic undercounting ‚Üí review agent integration points

### Recommended Next Steps
1. ‚úÖ **Proceed to Plan phase** - confidence is HIGH, no blockers
2. Validate Stripe metered billing limits (quick API docs check)
3. Confirm background job infra (ARQ/Celery) available
4. Add idempotency_key to UsageEvent model in design
5. Add circuit breaker to Stripe integration in design

---

## How This Analysis Feeds the Plan Phase

| Section | ‚Üí Plan Phase Usage |
|---------|-------------------|
| Recommended Approach (¬ß11) | ‚Üí High-level architecture in design.md |
| Failure Mitigations (¬ß5) | ‚Üí Error handling tasks: retry logic, reconciliation, alerts |
| Invariants (¬ß6) | ‚Üí DB constraints, validation logic in models |
| AI Delegation (¬ß10) | ‚Üí Mark tasks as "Safe for Ralph" vs "Needs review" |
| Observability (¬ß7) | ‚Üí Logging, metrics, monitoring tasks |
| Trade-off Positions (¬ß4) | ‚Üí Justify batch reporting, polling UI, hybrid storage |
| Red Flags (¬ß9) | ‚Üí Priority tasks: idempotency key, circuit breaker |

---

*Generated: 2026-02-03*
*Protocol: Full (11 steps)*
*Confidence: High*
*Red flags: 2 yellow (minor), 0 critical*
*Next phase: Plan ‚Üí `/plan FEAT-008`*
